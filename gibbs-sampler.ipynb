{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Author: Sachin K Salim\n# Date:    May 2021\n# \n# Description: Implementation of Gibbs Sampling from the paper \"GIBBS \n#               SAMPLING FOR THE UNINITIATED\" by Philip Resnik, Eric Hardisty","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nNotations\n---------\nV : number of words in the vocabulary\ni : index of the word in the vocabulary\n\nN : number of docs in the corpus\nj : index for documents\n\nZ : number of labels (=2)\nx : index of label\n\n\nγ_π : 1-D ndarray of len Z\n    hyperparameters of the Beta distribution\nγ_θ : 1-D ndarray of length V\n        hyperparameter vector for the multinomial prior\n        \n\nlabels : 1-D ndarray of len N\n\nclass_count : 1-D ndarray of length Z\n    Number of docs labeled x\n        \ndocs : 2-D ndarray of size NxV\n    List of all docs in BoW format\ndocs_0, docs_1 : 2-D ndarrays of size class_count_x*V\n    List of docs labeled x\n\nword_count : 2-D ndarray of size ZxV\n    number of times word i occurs in docs labeled x\n    \nθ : 2-D ndarray of size ZxV\n    θ_xi stands for probability of word i from distribution of class x\nθ_r : 1-D ndarray of length V\n    θ_r = (θ[0]/θ[1])\n\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Source code of load_data(): https://medium.com/swlh/sentiment-analysis-with-bag-of-words-4b9786e967ca\n# Dataset: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n\n# For cleaning the data\nimport re\nimport nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\n\n# For creating a bag of words\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndef load_data(doc_count = None, vocabulary_size = 1500):\n    \"\"\"loads data to do sentiment analysis\n\n    Parameters\n    ----------\n    doc_count : int (optional - Default(None))\n        Number of docs to be loaded from dataset\n    vocabulary_size : int (optional - Default(1500))\n        The number of words in vocabulary\n\n    Returns\n    -------\n    x : docs\n    y : labels\n    \"\"\"\n    \n    # Loading the data\n    dataset = pd.read_csv(\"../input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\", header = None, nrows = doc_count)\n    dataset = dataset.rename(columns={0: \"Review\", 1: \"Liked\"})\n    dataset['bLiked'] = (dataset['Liked'] == \"positive\").astype(int)\n    N = np.size(dataset, axis=0)\n    \n    # Cleaning the data\n    corpus = []\n    ps = PorterStemmer()\n    for i in range(0, N):\n        review = re.sub('[^a-zA-Z]', ' ', dataset['Review'][i])\n        review = review.lower()\n        review = review.split()\n        all_stopwords = stopwords.words('english')\n        all_stopwords.remove('not')\n        review = [ps.stem(word) for word in review if not word in set(all_stopwords)]\n        review = ' '.join(review)\n        corpus.append(review)\n        \n    # Creating a bag of words\n    cv = CountVectorizer(max_features = vocabulary_size)\n    x = cv.fit_transform(corpus).toarray()\n    y = dataset['bLiked'].values\n    \n    return x, y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_training_indices(training_ratio = 0.8):\n    \"\"\"Randomly initializes training indices using training_ratio\n\n    Parameters\n    ----------\n    training_ratio : float (optional - Default(0.8))\n        The approx ratio of training data to total data\n\n    Returns\n    -------\n    train_indices : 1-D ndarray of len N\n        a boolean array with True at indices of training data\n    \"\"\"\n    tdr = training_ratio\n    train_indices = np.random.choice(a=[True,False], size=N, p=[tdr, 1-tdr])\n    return train_indices\n\ndef is_training_doc(train_indices, j):\n    \"\"\"Determines if doc_j is a training data\"\"\"\n    return train_indices[j]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialization of the labels\ndef __initialize_labels(N, Z):\n    \"\"\"Initialization of the labels\n\n    Parameters\n    ----------\n    N : number of docs in the corpus\n    Z : number of labels\n\n    Returns\n    -------\n    γ_π : 1-D ndarray of len Z\n    labels : 1-D ndarray of len N\n    \"\"\"\n    \n    γ_π = np.ones(Z, dtype=int) # (γ_π_0, γ_π_1)\n\n    π = np.random.beta(γ_π[0], γ_π[1])\n    labels = np.random.binomial(n=1, p=π, size=N)\n    # assigning observed labels\n    labels[train_indices] = labels_orig[train_indices]\n    \n    return γ_π, labels\n\n# Initialization of θ\ndef __initialize_θ(V, Z):\n    \"\"\"Initialization of θ\n\n    Parameters\n    ----------\n    V : number of words in the vocabulary\n    Z : number of labels\n\n    Returns\n    -------\n    γ_θ : 1-D ndarray of length V\n    θ_r : 1-D ndarray of length V\n    \"\"\"\n    \n    # hyperparameter vector for the multinomial prior\n    γ_θ = np.ones(V, dtype=int)\n\n    θ = np.random.dirichlet(γ_θ, size=2)\n    θ_r = θ[0]/θ[1]\n    \n    return γ_θ, θ_r\n\ndef initialize(V, N, Z):\n    \"\"\"Initialization of the Sampler\n\n    Parameters\n    ----------\n    V : number of words in the vocabulary\n    N : number of docs in the corpus\n    Z : number of labels\n\n    Returns\n    -------\n    γ_π : 1-D ndarray of len Z\n    labels : 1-D ndarray of len N\n    γ_θ : 1-D ndarray of length V\n    θ_r : 1-D ndarray of length V\n    \"\"\"\n    \n    γ_π, labels = __initialize_labels(N, Z)\n    γ_θ, θ_r = __initialize_θ(V, Z)\n    \n    return γ_π, labels, γ_θ, θ_r","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update_label(doc_j, class_count, θ_r, γ_π):\n    \"\"\"Updating label_j by sampling from the conditional distribution\n\n    Parameters\n    ----------\n    doc_j (const) : 1-D ndarray of len V\n    class_count : 1-D ndarray of length Z\n    θ_r : 1-D ndarray of length V\n    γ_π (const) :  1-D ndarray of len Z\n\n    Returns\n    -------\n    L_j : int ∈ {0, 1}\n        updated label at index j\n    \"\"\"\n    \n    # In section 2.5.1, paper asks us to compute value_0 and value_1 separately and then\n    # normalize it to find π = value_0/(value_0+value_1). But value_0, value_1 may become\n    # infinitesimally small and thus program might treat it as 0. To avoid this, we instead\n    # compute f=value_0/value_1 instead of computing the values separately\n    term_1 = (class_count[0] + γ_π[0] - 1)/(class_count[1] + γ_π[1] - 1)\n    term_2 = np.product(θ_r**doc_j)\n    f = term_1 * term_2\n    \n    # π: probability of label 0\n    π = 1/(1 + f)\n    \n    L_j = np.random.binomial(n=1, p=π)\n    return L_j","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def __update_class_counts(labels):\n    \"\"\"\n    Updates class-counts which are used to resample\n    labels at the beginning of every iteration.\n    \n    Parameters\n    ----------\n    labels : 1-D ndarray of length N\n    \n    Returns\n    -------\n    class_count : 1-D ndarray of length Z\n    \"\"\"\n    \n    # class_count_x: No. of docs labeled x\n    class_count_0 = np.sum(labels == 0)\n    N = labels.size\n    class_count_1 = N - class_count_0\n    class_count = np.array([class_count_0, class_count_1])\n    \n    return class_count\n\ndef __update_word_counts(docs):\n    \"\"\"\n    Updates word-counts which are used to resample\n    theta at the beginning of every iteration.\n    \n    Parameters\n    ----------\n    docs (const) : 2-D ndarray of size NxV\n    \n    Returns\n    -------\n    word_count : 2-D ndarray of size ZxV\n    \"\"\"\n    \n    def __split(arr, cond):\n        \"\"\"Util function to split an array based on a condition\"\"\"\n        return (arr[cond], arr[~cond])\n\n    # docs_x: The set of documents labeled x\n    docs_0, docs_1 = __split(docs, labels == 0)\n    \n    # word_count_x: No. of times word i occurs in docs__x\n    word_count = np.array([np.sum(docs_0, axis=0), np.sum(docs_1, axis=0)])\n    \n    return word_count\n    \n\ndef update_counts(labels, docs):\n    \"\"\"\n    Updates class-counts and word-counts which are used to resample\n    labels and theta respectively, at the beginning of every iteration.\n    \n    Parameters\n    ----------\n    docs (const) : 2-D ndarray of size NxV\n    labels : 1-D ndarray of length N\n    \n    Returns\n    -------\n    class_count : 1-D ndarray of length Z\n    word_count : 2-D ndarray of size ZxV\n    \"\"\"\n    \n    class_count = __update_class_counts(labels)\n    word_count = __update_word_counts(docs)\n    \n    return class_count, word_count\n\ndef update_word_count_x(word_count_x, doc, change):\n    \"\"\"\n    Updates word-count-x (labeled x) by either reducing\n    or incrementing the doc's word-counts\n    \n    Parameters\n    ----------\n    word_count_x\n    doc (const) : 1-D ndarray of length V\n    change : either +1 or -1\n    \n    \"\"\"\n    word_count_x += change * doc\n    return word_count_x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def update_theta(word_count, γ_θ):\n    \"\"\"\n    Parameters\n    ----------\n    word_count : 2-D ndarray of size ZxV\n    γ_θ : 2-D ndarray of size ZxV\n    \n    Returns\n    -------\n    θ_r : 1-D ndarray of length V\n    \"\"\"    \n    θ_0 = np.random.dirichlet(word_count[0] + γ_θ)\n    θ_1 = np.random.dirichlet(word_count[1] + γ_θ)\n    θ_r = θ_0/θ_1\n    return θ_r","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_error(labels_sum, labels_orig, no_of_iterations, test_indices):\n    labels_exp = labels_sum/no_of_iterations\n    labels_exp = labels_exp.round().astype(int)\n    labels_error = labels_exp[test_indices]-labels_orig[test_indices]\n    return labels_error\n\ndef calculate_accuracy(labels_error):\n    accuracy = 100*(1 - np.mean(np.square(labels_error)))\n    return accuracy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"docs, labels_orig = load_data()\n\nZ = 2 # Number of labels\nN = np.size(docs, axis=0) # Number of documents\nV = np.size(docs, axis=1) # Number of words in the vocabulary\nV, N, Z","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Re-run from here ->\ntrain_indices = initialize_training_indices(training_ratio = 0)\n\nγ_π, labels, γ_θ, θ_r = initialize(V, N, Z)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"T = 20 # number of iterations\nB = 0 # burn-in\n\nlabels_sum = np.zeros(N, dtype=int)\n\nfor t in np.arange(1, T+1):\n    class_count, word_count = update_counts(labels, docs)\n    \n    for j in np.arange(N):\n         # if doc_j is a training doc, skip the iteration\n        if(is_training_doc(train_indices, j)):\n            continue\n\n        x = labels[j]\n        doc = docs[j]\n        \n        # For each word in doc_j, subtract its count in doc_j from its corresponding label's word-count\n        word_count[x] = update_word_count_x(word_count[x], doc, -1)\n        \n        # Subtract 1 from corresponding label's document-count\n        class_count[x] -= 1\n        \n        # Update L_j\n        x = labels[j] = update_label(doc, class_count, θ_r, γ_π)\n        \n        # For each word in doc_j, add its count in doc_j to its corresponding label's word-count\n        word_count[x] = update_word_count_x(word_count[x], doc, +1)\n        \n        # Add 1 to corresponding label's document-count\n        class_count[x] += 1\n        \n    # θ: theta\n    θ_r = update_theta(word_count, γ_θ)\n    \n    if(t<=B):\n        continue\n    \n    labels_sum += labels\n\nlabels_error = calculate_error(labels_sum, labels_orig, T-B, ~train_indices)\naccuracy = calculate_accuracy(labels_error)","metadata":{},"execution_count":null,"outputs":[]}]}